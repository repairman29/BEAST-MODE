# Public Repository ML Training - Legal & Ethical Guide

**Date:** January 5, 2026  
**Status:** âœ… **Compliant Approach Documented**

---

## ğŸ¯ Executive Summary

**Can we scan public repos for ML training?**

**Short Answer:** âœ… **YES, with important caveats**

**What's Allowed:**
- âœ… Scanning public repos via GitHub API
- âœ… Extracting metadata (stars, forks, file counts)
- âœ… Training on aggregated features (not source code)
- âœ… Using repository statistics for quality prediction

**What Requires Care:**
- âš ï¸ Respect repository licenses
- âš ï¸ Honor opt-out signals (`.ai_exclude` files)
- âš ï¸ Don't store full source code
- âš ï¸ Use aggregated/statistical data only

---

## ğŸ“‹ Legal Framework

### GitHub Terms of Service

**What GitHub Allows:**
1. âœ… **Public Repository Access** - Public repos are accessible via API
2. âœ… **Metadata Collection** - Stars, forks, issues, etc. are public data
3. âœ… **Fair Use** - GitHub considers ML training on public data as fair use
4. âš ï¸ **Opt-Out Mechanism** - Developers can exclude repos with `.ai_exclude` file

**Key Points:**
- Public repos are "public" - accessible to everyone
- GitHub API is the proper way to access public data
- Respect rate limits and API terms
- Honor opt-out mechanisms

### Copyright & Licensing

**Public â‰  Public Domain:**
- Public repos are still copyrighted
- Licenses govern use (MIT, Apache, GPL, etc.)
- Most open-source licenses allow use for any purpose
- Some licenses have restrictions (GPL requires derivative works to be GPL)

**Our Approach:**
- âœ… We only use **metadata** (not source code)
- âœ… We use **aggregated statistics** (stars, forks, file counts)
- âœ… We don't store or reproduce source code
- âœ… We respect licenses by not copying code

### Fair Use Doctrine

**What is Fair Use?**
- Using copyrighted material for research/analysis
- Transformative use (creating something new)
- Limited use (not reproducing entire works)

**Our Use Case:**
- âœ… **Transformative** - We're creating quality prediction models, not copying code
- âœ… **Limited** - We only use metadata/statistics, not source code
- âœ… **Research** - ML training for quality prediction
- âœ… **No Market Impact** - We're not competing with original code

**GitHub's Position:**
- GitHub considers ML training on public data as fair use
- This is the industry standard practice
- However, legal challenges exist (e.g., GitHub Copilot lawsuits)

---

## âœ… What We're Currently Doing (Compliant)

### 1. Data Collection

**What We Collect:**
- âœ… Repository metadata (stars, forks, issues)
- âœ… File structure (file counts, file types)
- âœ… Quality indicators (hasTests, hasCI, hasDocker)
- âœ… Language statistics
- âœ… Repository age and activity

**What We DON'T Collect:**
- âŒ Full source code files
- âŒ Code snippets or functions
- âŒ Actual code content
- âŒ Sensitive information

### 2. Data Usage

**How We Use Data:**
- âœ… Extract features (51 features from metadata)
- âœ… Train quality prediction models
- âœ… Aggregate statistics for analysis
- âœ… Create embeddings (semantic representations, not code)

**How We DON'T Use Data:**
- âŒ Reproduce or copy source code
- âŒ Train code generation models
- âŒ Store full repositories
- âŒ Compete with original code

### 3. Current Practice

**Repositories We Scan:**
- âœ… User's own connected repos (explicit permission)
- âœ… Public repos via GitHub API (public data)
- âœ… Respecting rate limits
- âœ… Using proper authentication

---

## ğŸš¨ What We Must Respect

### 1. Opt-Out Mechanisms

**`.ai_exclude` File:**
- GitHub allows developers to exclude repos from AI training
- If a repo has `.ai_exclude` file, we should skip it
- This is a developer's explicit opt-out signal

**Implementation:**
```javascript
// Check for .ai_exclude file
async function checkOptOut(owner, repo, octokit) {
  try {
    await octokit.repos.getContent({
      owner,
      repo,
      path: '.ai_exclude'
    });
    return true; // Opt-out detected
  } catch {
    return false; // No opt-out
  }
}
```

### 2. Repository Licenses

**License Types:**
- **Permissive** (MIT, Apache, BSD) - âœ… Usually OK
- **Copyleft** (GPL, AGPL) - âš ï¸ May have restrictions
- **Proprietary** - âŒ Don't use

**Our Approach:**
- âœ… We only use metadata (not code), so licenses don't apply
- âœ… But we should still respect developer intent
- âœ… Document which licenses we encounter

### 3. Rate Limiting

**GitHub API Limits:**
- Authenticated: 5,000 requests/hour
- Unauthenticated: 60 requests/hour
- Respect rate limits to avoid blocking

**Best Practices:**
- âœ… Use authenticated requests when possible
- âœ… Implement exponential backoff
- âœ… Cache results to reduce API calls
- âœ… Batch requests when possible

---

## ğŸ”’ Privacy & Security

### What We Store

**Allowed:**
- âœ… Repository metadata (public data)
- âœ… Aggregated statistics
- âœ… Feature vectors (derived from metadata)
- âœ… Quality scores (our predictions)

**Not Allowed:**
- âŒ Full source code
- âŒ Code snippets
- âŒ Sensitive information
- âŒ Private repository data (without permission)

### Data Retention

**Best Practices:**
- âœ… Keep only what's necessary for ML training
- âœ… Aggregate data when possible
- âœ… Remove identifying information
- âœ… Allow data deletion requests

---

## ğŸ“Š Recommended Approach

### Phase 1: Current Practice (Safe)

**What We Do:**
1. âœ… Scan user's own connected repos (explicit permission)
2. âœ… Extract metadata only (no source code)
3. âœ… Train on aggregated features
4. âœ… Respect rate limits

**Status:** âœ… **Compliant and Safe**

### Phase 2: Public Repo Scanning (With Safeguards)

**What We Can Add:**
1. âœ… Scan public repos via GitHub API
2. âœ… Check for `.ai_exclude` files (skip if present)
3. âœ… Only extract metadata (stars, forks, file counts)
4. âœ… Respect repository licenses
5. âœ… Document our practices

**Implementation:**
```javascript
async function scanPublicRepoForML(owner, repo, octokit) {
  // 1. Check opt-out
  const optedOut = await checkOptOut(owner, repo, octokit);
  if (optedOut) {
    console.log(`â­ï¸  Skipping ${owner}/${repo} - opted out via .ai_exclude`);
    return null;
  }

  // 2. Get metadata only (no source code)
  const metadata = await getRepositoryMetadata(owner, repo, octokit);
  
  // 3. Extract features (aggregated statistics)
  const features = extractFeatures(metadata);
  
  // 4. Return for training (no source code)
  return features;
}
```

### Phase 3: Ethical Best Practices

**Additional Safeguards:**
1. âœ… Public documentation of our practices
2. âœ… Opt-out mechanism for repo owners
3. âœ… Transparency about data usage
4. âœ… Regular compliance reviews

---

## ğŸ¯ Implementation Checklist

### Before Scanning Public Repos

- [ ] âœ… Implement `.ai_exclude` check
- [ ] âœ… Document data collection practices
- [ ] âœ… Update privacy policy
- [ ] âœ… Add license checking
- [ ] âœ… Implement rate limiting
- [ ] âœ… Create opt-out mechanism
- [ ] âœ… Test with small sample first

### During Scanning

- [ ] âœ… Respect rate limits
- [ ] âœ… Skip opted-out repos
- [ ] âœ… Only collect metadata
- [ ] âœ… Log all scans
- [ ] âœ… Handle errors gracefully

### After Scanning

- [ ] âœ… Aggregate data
- [ ] âœ… Remove identifying info
- [ ] âœ… Store securely
- [ ] âœ… Allow deletion requests
- [ ] âœ… Monitor for issues

---

## ğŸ“ Legal Recommendations

### 1. Document Everything

**What to Document:**
- What data we collect
- How we use it
- Where it's stored
- How to opt-out
- Contact information

### 2. Update Privacy Policy

**Add Section:**
- Public repository scanning
- Data collection practices
- Opt-out mechanisms
- License respect

### 3. Create Opt-Out Page

**Provide:**
- Clear instructions
- Easy opt-out process
- Confirmation of opt-out
- Contact for questions

### 4. Regular Compliance Review

**Review:**
- Legal landscape changes
- New opt-out mechanisms
- License requirements
- Best practices updates

---

## ğŸš€ Next Steps

### Immediate (Safe)

1. âœ… **Continue current practice** (user's own repos)
2. âœ… **Document what we do** (this guide)
3. âœ… **Update privacy policy** (add ML training section)

### Short-term (With Safeguards)

1. â³ **Implement `.ai_exclude` check**
2. â³ **Add license checking**
3. â³ **Create public repo scanner** (with safeguards)
4. â³ **Test with small sample**

### Long-term (Best Practices)

1. â¸ï¸ **Public opt-out mechanism**
2. â¸ï¸ **Transparency dashboard**
3. â¸ï¸ **Regular compliance audits**
4. â¸ï¸ **Legal review** (if scaling)

---

## ğŸ“š References

### Legal Documents

- [GitHub Terms of Service](https://docs.github.com/en/site-policy/github-terms/github-terms-of-service)
- [GitHub API Terms](https://docs.github.com/en/rest/overview/terms-of-service)
- [Fair Use Doctrine](https://www.copyright.gov/fair-use/)

### Industry Practices

- GitHub Copilot (uses public repos, under legal challenge)
- OpenAI Codex (trained on public code)
- Google Code Search (indexes public repos)

### Best Practices

- Respect opt-out mechanisms
- Use metadata only
- Don't store source code
- Document everything
- Be transparent

---

## âœ… Conclusion

**Can we scan public repos for ML training?**

**YES** - With proper safeguards:
- âœ… Only metadata (not source code)
- âœ… Respect opt-outs (`.ai_exclude`)
- âœ… Honor licenses
- âœ… Document practices
- âœ… Be transparent

**Our Current Practice:**
- âœ… Already compliant (using user's own repos)
- âœ… Only metadata collection
- âœ… No source code storage
- âœ… Aggregated features only

**Next Steps:**
- â³ Implement `.ai_exclude` check
- â³ Add public repo scanning (with safeguards)
- â³ Update documentation
- â³ Test with small sample

---

**Status:** âœ… **Compliant Approach | Ready for Implementation**

